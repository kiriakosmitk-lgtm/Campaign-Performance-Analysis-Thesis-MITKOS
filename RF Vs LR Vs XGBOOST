"""
Î£Î¥Î“ÎšÎ¡Î™Î£Î— 3 ÎœÎŸÎÎ¤Î•Î›Î©Î 
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, roc_auc_score
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
import warnings
warnings.filterwarnings('ignore')

plt.rcParams['font.family'] = 'DejaVu Sans'

# Î¦ÎŸÎ¡Î¤Î©Î£Î— & ÎšÎ‘Î˜Î‘Î¡Î™Î£ÎœÎŸÎ£ Î”Î•Î”ÎŸÎœÎ•ÎÎ©Î

print("\n" + "="*70)
print("Î¦ÎŸÎ¡Î¤Î©Î£Î— Î”Î•Î”ÎŸÎœÎ•ÎÎ©Î")
print("="*70)

df = pd.read_csv("Meta_Data.csv", encoding='UTF-8')
print(f"âœ“ Î¦Î¿ÏÏ„ÏÎ¸Î·ÎºÎ±Î½ {df.shape[0]} Î´ÎµÎ´Î¿Î¼Î­Î½Î±")

# ÎšÎ±Î¸Î±ÏÎ¹ÏƒÎ¼ÏŒÏ‚
threshold = 0.4 * len(df)
df = df.dropna(thresh=threshold, axis=1)
df.fillna(0, inplace=True)

for col in df.columns:
    if df[col].dtype == 'object':
        try:
            df[col] = df[col].str.replace(',', '.').astype(float)
        except:
            pass

df.columns = df.columns.str.strip().str.replace(' ', '_').str.replace('(', '').str.replace(')', '')

# Î¤Î‘ÎÎ™ÎÎŸÎœÎ—Î£Î— ÎšÎ‘ÎœÎ Î‘ÎÎ™Î©Î

def classify_campaign(name):
    name_lower = str(name).lower()
    if 'remarketing' in name_lower: return 'Remarketing'
    if 'prospect' in name_lower: return 'Prospecting'
    if 'traffic' in name_lower: return 'Traffic'
    if 'engagement' in name_lower: return 'Engagement'
    if any(w in name_lower for w in ['conversion', 'purchase']): return 'Conversions'
    if any(w in name_lower for w in ['sales', 'christmas']): return 'Seasonal Sales'
    if 'awareness' in name_lower: return 'Brand Awareness'
    return 'Catalog Sales'

def classify_success(row):
    roas = (row.get('Î‘Î¾Î¯Î±_Î¼ÎµÏ„Î±Ï„ÏÎ¿Ï€ÏÎ½_Î±Ï€ÏŒ_Î±Î³Î¿ÏÎ­Ï‚', 0) / row.get('ÎˆÎ¾Î¿Î´Î±_EUR', 1) if row.get('ÎˆÎ¾Î¿Î´Î±_EUR', 0) > 0 else 0)
    type_ = row['Î¤ÏÏ€Î¿Ï‚_ÎšÎ±Î¼Ï€Î¬Î½Î¹Î±Ï‚']
    
    if type_ == 'Conversions': return int((roas >= 2.0) or (row['Î‘Î³Î¿ÏÎ­Ï‚'] >= 3))
    elif type_ == 'Remarketing': return int(row['CTR_ÏŒÎ»Î±'] >= 2.0)
    elif type_ == 'Prospecting': return int(row['Î‘Ï€Î®Ï‡Î·ÏƒÎ·'] >= 3000)
    elif type_ == 'Catalog Sales': return int(row['Î‘Î³Î¿ÏÎ­Ï‚'] >= 2)
    elif type_ == 'Traffic': return int(row['ÎšÏŒÏƒÏ„Î¿Ï‚_Î±Î½Î¬_ÎºÎ»Î¹Îº_ÏŒÎ»Î±_EUR'] <= 0.5)
    return int(row['CTR_ÏŒÎ»Î±'] >= 1.5)

df['Î¤ÏÏ€Î¿Ï‚_ÎšÎ±Î¼Ï€Î¬Î½Î¹Î±Ï‚'] = df['ÎŒÎ½Î¿Î¼Î±_ÎµÎºÏƒÏ„ÏÎ±Ï„ÎµÎ¯Î±Ï‚'].apply(classify_campaign)
df['Î•Ï€Î¹Ï„Ï…Ï‡Î¯Î±'] = df.apply(classify_success, axis=1)

print(f"Î•Ï€Î¹Ï„Ï…Ï‡ÎµÎ¯Ï‚: {df['Î•Ï€Î¹Ï„Ï…Ï‡Î¯Î±'].sum()}")

# Î Î¡ÎŸÎ•Î¤ÎŸÎ™ÎœÎ‘Î£Î™Î‘

features = ['CTR_ÏŒÎ»Î±', 'CPM_ÎºÏŒÏƒÏ„Î¿Ï‚_Î±Î½Î¬_1.000_ÎµÎ¼Ï†Î±Î½Î¯ÏƒÎµÎ¹Ï‚_EUR', 
            'ÎšÏŒÏƒÏ„Î¿Ï‚_Î±Î½Î¬_ÎºÎ»Î¹Îº_ÏŒÎ»Î±_EUR', 'Î‘Ï€Î®Ï‡Î·ÏƒÎ·', 'Î•Î¼Ï†Î±Î½Î¯ÏƒÎµÎ¹Ï‚', 
            'Î£Ï…Ï‡Î½ÏŒÏ„Î·Ï„Î±', 'Î¤ÏÏ€Î¿Ï‚_ÎšÎ±Î¼Ï€Î¬Î½Î¹Î±Ï‚']

X = df[features].copy()
y = df['Î•Ï€Î¹Ï„Ï…Ï‡Î¯Î±']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)

numeric_features = X.select_dtypes(include=['float64', 'int64']).columns.tolist()
categorical_features = ['Î¤ÏÏ€Î¿Ï‚_ÎšÎ±Î¼Ï€Î¬Î½Î¹Î±Ï‚']

preprocessor = ColumnTransformer([
    ('num', StandardScaler(), numeric_features),
    ('cat', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'), categorical_features)
])

print(f"âœ“ Train/Test: {len(X_train)}/{len(X_test)}")

# Î•ÎšÎ Î‘Î™Î”Î•Î¥Î£Î— 3 ÎœÎŸÎÎ¤Î•Î›Î©Î

print("\n" + "="*70)
print("Î•ÎšÎ Î‘Î™Î”Î•Î¥Î£Î— ÎœÎŸÎÎ¤Î•Î›Î©Î")
print("="*70)

results = {}

# RANDOM FOREST
print("\n1. Random Forest...")
rf = Pipeline([
    ('preprocessor', preprocessor),
    ('model', RandomForestClassifier(n_estimators=150, max_depth=15, random_state=42, n_jobs=-1))
])
rf.fit(X_train, y_train)
y_pred_rf = rf.predict(X_test)
y_proba_rf = rf.predict_proba(X_test)[:, 1]

results['Random Forest'] = {
    'Accuracy': accuracy_score(y_test, y_pred_rf),
    'Precision': precision_score(y_test, y_pred_rf, zero_division=0),
    'Recall': recall_score(y_test, y_pred_rf, zero_division=0),
    'F1-Score': f1_score(y_test, y_pred_rf, zero_division=0),
    'AUC-ROC': roc_auc_score(y_test, y_proba_rf)
}
print(f"F1: {results['Random Forest']['F1-Score']:.2f}")

# LOGISTIC REGRESSION
print("\n2. Logistic Regression...")
lr = Pipeline([
    ('preprocessor', preprocessor),
    ('model', LogisticRegression(C=1.0, max_iter=2000, class_weight='balanced', random_state=42, n_jobs=-1))
])
lr.fit(X_train, y_train)
y_pred_lr = lr.predict(X_test)
y_proba_lr = lr.predict_proba(X_test)[:, 1]

results['Logistic Regression'] = {
    'Accuracy': accuracy_score(y_test, y_pred_lr),
    'Precision': precision_score(y_test, y_pred_lr, zero_division=0),
    'Recall': recall_score(y_test, y_pred_lr, zero_division=0),
    'F1-Score': f1_score(y_test, y_pred_lr, zero_division=0),
    'AUC-ROC': roc_auc_score(y_test, y_proba_lr)
}
print(f" F1: {results['Logistic Regression']['F1-Score']:.2f}")

# XGBOOST
try:
    import xgboost as xgb
    print("\n3. XGBoost...")
    
    X_train_proc = preprocessor.fit_transform(X_train)
    X_test_proc = preprocessor.transform(X_test)
    
    xgb_model = xgb.XGBClassifier(n_estimators=150, max_depth=6, learning_rate=0.05, 
                                   random_state=42, eval_metric='logloss', use_label_encoder=False)
    xgb_model.fit(X_train_proc, y_train, verbose=False)
    y_pred_xgb = xgb_model.predict(X_test_proc)
    y_proba_xgb = xgb_model.predict_proba(X_test_proc)[:, 1]
    
    results['XGBoost'] = {
        'Accuracy': accuracy_score(y_test, y_pred_xgb),
        'Precision': precision_score(y_test, y_pred_xgb, zero_division=0),
        'Recall': recall_score(y_test, y_pred_xgb, zero_division=0),
        'F1-Score': f1_score(y_test, y_pred_xgb, zero_division=0),
        'AUC-ROC': roc_auc_score(y_test, y_proba_xgb)
    }
    print(f"F1: {results['XGBoost']['F1-Score']:.2f}")
except:
    print("\n3. XGBoost... (Î´ÎµÎ½ Î´Î¿Ï…Î»ÎµÏÎµÎ¹)")

# Î Î™ÎÎ‘ÎšÎ‘Î£ Î‘Î ÎŸÎ¤Î•Î›Î•Î£ÎœÎ‘Î¤Î©Î

print("\n" + "="*70)
print("Î Î™ÎÎ‘ÎšÎ‘Î£ Î‘Î ÎŸÎ¤Î•Î›Î•Î£ÎœÎ‘Î¤Î©Î")
print("="*70 + "\n")

df_results = pd.DataFrame(results).T
print(df_results.round(2).to_string())

# ÎšÎ±Î»ÏÏ„ÎµÏÎ¿ Î¼Î¿Î½Ï„Î­Î»Î¿
best_model = df_results['F1-Score'].idxmax()
print(f"\nğŸ† ÎšÎ‘Î›Î¥Î¤Î•Î¡ÎŸ: {best_model} (F1: {df_results.loc[best_model, 'F1-Score']:.2f})")

# Î”Î™Î‘Î“Î¡Î‘ÎœÎœÎ‘

print("\n" + "="*70)
print("Î”Î—ÎœÎ™ÎŸÎ¥Î¡Î“Î™Î‘ Î”Î™Î‘Î“Î¡Î‘ÎœÎœÎ‘Î¤ÎŸÎ£")
print("="*70)

fig, ax = plt.subplots(figsize=(12, 6))

models = df_results.index.tolist()
x = np.arange(len(models))
width = 0.15

colors = ['#2ca02c', '#1f77b4', '#ff7f0e', '#d62728', '#9467bd']

bars1 = ax.bar(x - 2*width, df_results['Accuracy'], width, label='Accuracy', color=colors[0], alpha=0.9)
bars2 = ax.bar(x - width, df_results['Precision'], width, label='Precision', color=colors[1], alpha=0.9)
bars3 = ax.bar(x, df_results['Recall'], width, label='Recall', color=colors[2], alpha=0.9)
bars4 = ax.bar(x + width, df_results['F1-Score'], width, label='F1-Score', color=colors[3], alpha=0.9)
bars5 = ax.bar(x + 2*width, df_results['AUC-ROC'], width, label='AUC-ROC', color=colors[4], alpha=0.9)

# Î ÏÎ¿ÏƒÎ¸Î®ÎºÎ· Ï„Î¹Î¼ÏÎ½
all_bars = [bars1, bars2, bars3, bars4, bars5]
for bars in all_bars:
    for bar in bars:
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                f'{height:.2f}', ha='center', va='bottom', fontsize=9, fontweight='bold')

ax.set_ylabel('Score', fontweight='bold', fontsize=12)
ax.set_xlabel('ÎœÎ¿Î½Ï„Î­Î»Î±', fontweight='bold', fontsize=12)
ax.set_title('Î£ÏÎ³ÎºÏÎ¹ÏƒÎ· 3 ÎœÎ¿Î½Ï„Î­Î»Ï‰Î½ ÎœÎ·Ï‡Î±Î½Î¹ÎºÎ®Ï‚ ÎœÎ¬Î¸Î·ÏƒÎ·Ï‚', fontweight='bold', fontsize=14)
ax.set_xticks(x)
ax.set_xticklabels(models, fontsize=11)
ax.legend(fontsize=10, loc='upper right', ncol=5)
ax.set_ylim([0, 1.05])
ax.grid(axis='y', alpha=0.3)

plt.tight_layout()
plt.savefig('comparison.png', dpi=300, bbox_inches='tight')
print("Î”Î¹Î¬Î³ÏÎ±Î¼Î¼Î±: comparison.png")
plt.show()
